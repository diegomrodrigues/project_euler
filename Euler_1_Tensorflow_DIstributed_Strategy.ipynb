{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMANrKZH03qveNsDSo71pEi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegomrodrigues/project_euler/blob/main/Euler_1_Tensorflow_DIstributed_Strategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxj1toARIyhj",
        "outputId": "240f60a3-29a7-46a4-b9a3-f61c43befd83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A soma dos múltiplos de 3 ou 5 abaixo de 1000 é: 233168\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define um limite para o nosso problema\n",
        "limite = 1000\n",
        "\n",
        "# Cria um tensor com todos os números naturais até 'limite-1' (999)\n",
        "numeros = tf.range(limite)\n",
        "\n",
        "# Cria uma máscara booleana para filtrar múltiplos de 3 ou 5\n",
        "mascara = (numeros % 3 == 0) | (numeros % 5 == 0)\n",
        "\n",
        "# Aplica a máscara para obter apenas os múltiplos de 3 ou 5\n",
        "multiplos = tf.boolean_mask(numeros, mascara)\n",
        "\n",
        "# Calcula a soma dos elementos filtrados\n",
        "soma = tf.reduce_sum(multiplos)\n",
        "\n",
        "# Executa o cálculo\n",
        "print(\"A soma dos múltiplos de 3 ou 5 abaixo de 1000 é:\", soma.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def soma_multiplos(limite):\n",
        "    # Cria um tensor com todos os números naturais até 'limite-1'\n",
        "    numeros = tf.range(limite)\n",
        "\n",
        "    # Cria uma máscara booleana para filtrar múltiplos de 3 ou 5\n",
        "    mascara = (numeros % 3 == 0) | (numeros % 5 == 0)\n",
        "\n",
        "    # Aplica a máscara para obter apenas os múltiplos de 3 ou 5\n",
        "    multiplos = tf.boolean_mask(numeros, mascara)\n",
        "\n",
        "    # Calcula a soma dos elementos filtrados\n",
        "    return tf.reduce_sum(multiplos)\n",
        "\n",
        "# Executa a função tf.function para o problema específico\n",
        "limite = 1000\n",
        "soma = soma_multiplos(limite)\n",
        "print(\"A soma dos múltiplos de 3 ou 5 abaixo de 1000 é:\", soma.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUdUqetvI61k",
        "outputId": "bb4cb0c4-c42c-46f6-85b3-99a4b9142f33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A soma dos múltiplos de 3 ou 5 abaixo de 1000 é: 233168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def soma_multiplos_otimizada(limite):\n",
        "    # Cria um tensor com todos os números naturais até 'limite-1'\n",
        "    numeros = tf.range(limite)\n",
        "\n",
        "    # Calcula a soma diretamente usando operações vetoriais\n",
        "    # A condição produz um tensor de 0s e 1s, que são multiplicados pelos números e somados\n",
        "    return tf.reduce_sum(numeros * tf.cast((numeros % 3 == 0) | (numeros % 5 == 0), tf.int32))\n",
        "\n",
        "# Executa a função tf.function otimizada para o problema específico\n",
        "limite = 1000\n",
        "soma = soma_multiplos_otimizada(limite)\n",
        "print(\"A soma dos múltiplos de 3 ou 5 abaixo de 1000 é:\", soma.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F59IZ0dZJNQj",
        "outputId": "d8a63192-2740-4622-a985-6810d57a010f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A soma dos múltiplos de 3 ou 5 abaixo de 1000 é: 233168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a estratégia de distribuição para múltiplas GPUs\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print('Número de dispositivos: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Cria o cálculo dentro do escopo da estratégia\n",
        "with strategy.scope():\n",
        "    @tf.function\n",
        "    def soma_multiplos_otimizada(limite):\n",
        "        # Cria um tensor com todos os números naturais até 'limite-1'\n",
        "        numeros = tf.range(limite)\n",
        "\n",
        "        # Calcula a soma diretamente usando operações vetoriais\n",
        "        return tf.reduce_sum(numeros * tf.cast((numeros % 3 == 0) | (numeros % 5 == 0), tf.int32))\n",
        "\n",
        "    # Define o limite para o problema específico\n",
        "    limite = 10**9\n",
        "\n",
        "# Executa a função otimizada em múltiplas GPUs\n",
        "soma = soma_multiplos_otimizada(limite)\n",
        "print(\"A soma dos múltiplos de 3 ou 5 abaixo de 1000 é:\", soma.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVMRLMLWJ9Wh",
        "outputId": "633408ba-ada4-4f84-8e31-ee81af4c2d36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de dispositivos: 1\n",
            "A soma dos múltiplos de 3 ou 5 abaixo de 1000 é: 631780268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "LIMIT = 10**16\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('Número de dispositivos: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "with strategy.scope():\n",
        "    @tf.function(jit_compile=True)\n",
        "    def sum_multiples_optimized(limit):\n",
        "        \"\"\"\n",
        "        Calcula a soma de todos os múltiplos de 3 ou 5 abaixo do limite especificado.\n",
        "\n",
        "        Args:\n",
        "            limit (int): O limite superior (exclusivo) até o qual calcular a soma.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: A soma dos múltiplos de 3 ou 5 abaixo do limite.\n",
        "        \"\"\"\n",
        "        numbers = tf.range(limit)\n",
        "        is_multiple_of_3_or_5 = tf.math.logical_or(tf.math.mod(numbers, 3) == 0,\n",
        "                                                   tf.math.mod(numbers, 5) == 0)\n",
        "        multiples = numbers * tf.cast(is_multiple_of_3_or_5, tf.int64)\n",
        "        return tf.reduce_sum(multiples)\n",
        "\n",
        "sum_result = sum_multiples_optimized(LIMIT)\n",
        "print(f\"A soma dos múltiplos de 3 ou 5 abaixo de {LIMIT} é: {sum_result.numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "hSLzuvBpK76L",
        "outputId": "a03ea286-ce8c-4109-b11b-c8022f59fea1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de dispositivos: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "Number of physical blocks (70368744177664) does not fit in an i32 in tiling scheme: dims_in_elems = {1, 70368744177664, 143}, tile_sizes = {1, 1, 16}, num_threads = {1, 1, 32}, indexing_order = strided, vector_size = 1, thread_id_virtual_scaling = 1, tiling_dimensions = {1, 2} [Op:__inference_sum_multiples_optimized_119]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5fb079824711>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0msum_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_multiples_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"A soma dos múltiplos de 3 ou 5 abaixo de {LIMIT} é: {sum_result.numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Number of physical blocks (70368744177664) does not fit in an i32 in tiling scheme: dims_in_elems = {1, 70368744177664, 143}, tile_sizes = {1, 1, 16}, num_threads = {1, 1, 32}, indexing_order = strided, vector_size = 1, thread_id_virtual_scaling = 1, tiling_dimensions = {1, 2} [Op:__inference_sum_multiples_optimized_119]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a estratégia de distribuição para múltiplas GPUs\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print('Número de dispositivos: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Define o limite para o problema específico\n",
        "LIMIT = 10**16\n",
        "\n",
        "# Cria o cálculo dentro do escopo da estratégia\n",
        "with strategy.scope():\n",
        "    @tf.function(jit_compile=True)\n",
        "    def sum_multiples_optimized(limit):\n",
        "        \"\"\"\n",
        "        Calcula a soma de todos os múltiplos de 3 ou 5 abaixo do limite especificado.\n",
        "\n",
        "        Args:\n",
        "            limit (int): O limite superior (exclusivo) até o qual calcular a soma.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: A soma dos múltiplos de 3 ou 5 abaixo do limite.\n",
        "        \"\"\"\n",
        "        numbers = tf.range(limit)\n",
        "        is_multiple_of_3_or_5 = tf.math.logical_or(tf.math.mod(numbers, 3) == 0,\n",
        "                                                   tf.math.mod(numbers, 5) == 0)\n",
        "        multiples = numbers * tf.cast(is_multiple_of_3_or_5, tf.int64)\n",
        "        return tf.reduce_sum(multiples)\n",
        "\n",
        "# Executa a função otimizada em múltiplas GPUs\n",
        "sum_result = sum_multiples_optimized(LIMIT)\n",
        "print(f\"A soma dos múltiplos de 3 ou 5 abaixo de {LIMIT} é: {sum_result.numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "vClOUgyuW3Pm",
        "outputId": "ff9d9372-84ef-446f-d81b-c30de5cd16fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de dispositivos: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "Number of physical blocks (70368744177664) does not fit in an i32 in tiling scheme: dims_in_elems = {1, 70368744177664, 143}, tile_sizes = {1, 1, 16}, num_threads = {1, 1, 32}, indexing_order = strided, vector_size = 1, thread_id_virtual_scaling = 1, tiling_dimensions = {1, 2} [Op:__inference_sum_multiples_optimized_144]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c1fd2828d424>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Executa a função otimizada em múltiplas GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0msum_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_multiples_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"A soma dos múltiplos de 3 ou 5 abaixo de {LIMIT} é: {sum_result.numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Number of physical blocks (70368744177664) does not fit in an i32 in tiling scheme: dims_in_elems = {1, 70368744177664, 143}, tile_sizes = {1, 1, 16}, num_threads = {1, 1, 32}, indexing_order = strided, vector_size = 1, thread_id_virtual_scaling = 1, tiling_dimensions = {1, 2} [Op:__inference_sum_multiples_optimized_144]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a estratégia de distribuição para múltiplas GPUs\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print('Número de dispositivos: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Define o limite para o problema específico\n",
        "LIMIT = 10**16\n",
        "CHUNK_SIZE = 10**12  # Define o tamanho do bloco para cada GPU processar\n",
        "\n",
        "# Cria o cálculo dentro do escopo da estratégia\n",
        "with strategy.scope():\n",
        "    @tf.function(jit_compile=True)\n",
        "    def compute_chunk(start, end):\n",
        "        \"\"\" Computa a soma dos múltiplos de 3 ou 5 em um intervalo específico. \"\"\"\n",
        "        sum_multiples = tf.constant(0, dtype=tf.int64)\n",
        "        for number in tf.range(start, end):\n",
        "            if tf.math.logical_or(number % 3 == 0, number % 5 == 0):\n",
        "                sum_multiples += number\n",
        "        return sum_multiples\n",
        "\n",
        "    def sum_multiples_optimized(limit):\n",
        "        \"\"\" Distribui o cálculo da soma dos múltiplos de 3 ou 5 por múltiplas GPUs. \"\"\"\n",
        "        num_chunks = (limit + CHUNK_SIZE - 1) // CHUNK_SIZE\n",
        "        results = []\n",
        "\n",
        "        for chunk_index in range(num_chunks):\n",
        "            start = chunk_index * CHUNK_SIZE\n",
        "            end = tf.minimum((chunk_index + 1) * CHUNK_SIZE, limit)\n",
        "            results.append(strategy.run(compute_chunk, args=(start, end)))\n",
        "\n",
        "        # Soma os resultados de todos os chunks\n",
        "        total_sum = tf.reduce_sum(strategy.experimental_local_results(results))\n",
        "        return total_sum\n",
        "\n",
        "# Executa a função otimizada\n",
        "sum_result = sum_multiples_optimized(LIMIT)\n",
        "print(f\"A soma dos múltiplos de 3 ou 5 abaixo de {LIMIT} é: {sum_result.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO_XvP0_irzB",
        "outputId": "2f714201-7e88-4a18-a92e-9a7384044bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de dispositivos: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function compute_chunk at 0x7808a4556a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function compute_chunk at 0x7808a4556a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the distribution strategy for multiple GPUs\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Define the limit for the specific problem\n",
        "LIMIT = 10**16\n",
        "BATCH_SIZE = 10**8  # Adjustable based on available memory and GPU count\n",
        "\n",
        "# Utilizing vectorized operations for batch processing\n",
        "@tf.function(jit_compile=True)\n",
        "def compute_multiples_sum(batch_start, batch_end):\n",
        "    numbers = tf.range(batch_start, batch_end, dtype=tf.int64)\n",
        "    mask = tf.logical_or(tf.equal(numbers % 3, 0), tf.equal(numbers % 5, 0))\n",
        "    selected_numbers = tf.boolean_mask(numbers, mask)\n",
        "    return tf.reduce_sum(selected_numbers)\n",
        "\n",
        "# Distributing the batch computation across multiple GPUs\n",
        "def distributed_sum_multiples(limit):\n",
        "    num_batches = (limit + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "    total_sum = tf.constant(0, dtype=tf.int64)\n",
        "\n",
        "    for batch_index in tf.range(num_batches):\n",
        "        batch_start = batch_index * BATCH_SIZE\n",
        "        batch_end = tf.minimum((batch_index + 1) * BATCH_SIZE, limit)\n",
        "        batch_sum = strategy.run(compute_multiples_sum, args=(batch_start, batch_end))\n",
        "        total_sum += strategy.reduce(tf.distribute.ReduceOp.SUM, batch_sum, axis=None)\n",
        "\n",
        "    return total_sum\n",
        "\n",
        "# Execute the optimized function\n",
        "sum_result = distributed_sum_multiples(LIMIT)\n",
        "print(f\"The sum of multiples of 3 or 5 below {LIMIT} is: {sum_result.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "QGZOv27HjpXs",
        "outputId": "f132c501-e98f-4741-acba-d20581df71b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Requires start <= limit when delta > 0: 1900000000/1874919424\n\nStack trace for op definition: \nFile \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\nFile \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\nFile \"<ipython-input-1-56c8d46c0f38>\", line 15, in compute_multiples_sum\n\n\t [[{{node range}}]]\n\ttf2xla conversion failed while converting __inference_compute_multiples_sum_67[_XlaMustCompile=true,config_proto=6001324581131673121,executor_type=11160318154034397263]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions. [Op:__inference_compute_multiples_sum_67]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-56c8d46c0f38>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Execute the optimized function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0msum_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_sum_multiples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The sum of multiples of 3 or 5 below {LIMIT} is: {sum_result.numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-56c8d46c0f38>\u001b[0m in \u001b[0;36mdistributed_sum_multiples\u001b[0;34m(limit)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbatch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mbatch_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mbatch_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_multiples_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtotal_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceOp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1679\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1680\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1681\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3271\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     return mirrored_run.call_for_each_replica(\n\u001b[0m\u001b[1;32m    701\u001b[0m         self._container_strategy(), fn, args, kwargs)\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     if fn._jit_compile and all(  # pylint: disable=protected-access\n\u001b[1;32m     67\u001b[0m         [_is_gpu_device(d) for d in strategy.extended.worker_devices]):\n\u001b[0;32m---> 68\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_cfer_fn_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_result\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    384\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mex_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mstop_on_exception\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=bare-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m               self._var_scope, reuse=self.replica_id > 0), \\\n\u001b[1;32m    386\u001b[0m           \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Requires start <= limit when delta > 0: 1900000000/1874919424\n\nStack trace for op definition: \nFile \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\nFile \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\nFile \"<ipython-input-1-56c8d46c0f38>\", line 15, in compute_multiples_sum\n\n\t [[{{node range}}]]\n\ttf2xla conversion failed while converting __inference_compute_multiples_sum_67[_XlaMustCompile=true,config_proto=6001324581131673121,executor_type=11160318154034397263]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions. [Op:__inference_compute_multiples_sum_67]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Number of GPUs available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Initialize TensorFlow distribution strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define the limit for the computation\n",
        "LIMIT = 10**16  # Reduced for demonstration, adjust as needed based on memory constraints\n",
        "BATCH_SIZE = 10**5  # This size is reasonable for demonstration purposes\n",
        "\n",
        "@tf.function\n",
        "def compute_multiples_sum(batch_start, batch_end):\n",
        "    numbers = tf.range(batch_start, batch_end, dtype=tf.int64)\n",
        "    mask = tf.logical_or(tf.equal(numbers % 3, 0), tf.equal(numbers % 5, 0))\n",
        "    selected_numbers = tf.boolean_mask(numbers, mask)\n",
        "    return tf.reduce_sum(selected_numbers)\n",
        "\n",
        "# Using TensorFlow distribution strategy\n",
        "with strategy.scope():\n",
        "    def distributed_sum_multiples(limit):\n",
        "        num_batches = (limit + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "        total_sum = tf.constant(0, dtype=tf.int64)\n",
        "\n",
        "        for batch_index in tf.range(num_batches):\n",
        "            batch_start = batch_index * BATCH_SIZE\n",
        "            batch_end = tf.minimum((batch_index + 1) * BATCH_SIZE, limit)\n",
        "            batch_sum = strategy.run(compute_multiples_sum, args=(batch_start, batch_end))\n",
        "            total_sum += strategy.reduce(tf.distribute.ReduceOp.SUM, batch_sum, axis=None)\n",
        "\n",
        "        return total_sum\n",
        "\n",
        "# Execute the optimized function\n",
        "sum_result = distributed_sum_multiples(LIMIT)\n",
        "print(f\"The sum of multiples of 3 or 5 below {LIMIT} is: {sum_result.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "Z42hwv19kD7j",
        "outputId": "758b8578-e8cc-48e8-ac50-ae0295c4ca46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "Number of GPUs available: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__Range_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[100000000000] and type int64 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Range}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:Range] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-245cab81ccdf>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Execute the optimized function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0msum_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_sum_multiples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The sum of multiples of 3 or 5 below {LIMIT} is: {sum_result.numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-245cab81ccdf>\u001b[0m in \u001b[0;36mdistributed_sum_multiples\u001b[0;34m(limit)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtotal_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mbatch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mbatch_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Range_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[100000000000] and type int64 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Range}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:Range] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Number of GPUs available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Initialize TensorFlow distribution strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define the limit for the computation\n",
        "LIMIT = 10**10  # Adjust as needed\n",
        "BATCH_SIZE = 10**5  # Reduce if necessary\n",
        "\n",
        "def compute_multiples_sum(batch_start, batch_end):\n",
        "    # Explicitly place the range operation on CPU\n",
        "    with tf.device('/CPU:0'):\n",
        "        numbers = tf.range(batch_start, batch_end, dtype=tf.int32)  # Using tf.int32 to save memory\n",
        "    mask = tf.logical_or(tf.equal(numbers % 3, 0), tf.equal(numbers % 5, 0))\n",
        "    selected_numbers = tf.boolean_mask(numbers, mask)\n",
        "    return tf.reduce_sum(selected_numbers)\n",
        "\n",
        "# Using TensorFlow distribution strategy\n",
        "with strategy.scope():\n",
        "    @tf.function\n",
        "    def distributed_sum_multiples(limit):\n",
        "        num_batches = (limit + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "        total_sum = tf.constant(0, dtype=tf.int32)  # Using tf.int32 to save memory\n",
        "\n",
        "        for batch_index in tf.range(num_batches):\n",
        "            batch_start = batch_index * BATCH_SIZE\n",
        "            batch_end = tf.minimum((batch_index + 1) * BATCH_SIZE, limit)\n",
        "            batch_sum = strategy.run(compute_multiples_sum, args=(batch_start, batch_end))\n",
        "            total_sum += strategy.reduce(tf.distribute.ReduceOp.SUM, batch_sum, axis=None)\n",
        "\n",
        "        return total_sum\n",
        "\n",
        "# Execute the optimized function\n",
        "sum_result = distributed_sum_multiples(LIMIT)\n",
        "print(f\"The sum of multiples of 3 or 5 below {LIMIT} is: {sum_result.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "BqXl8YE_kUN4",
        "outputId": "9ee8a769-6cfb-4321-99eb-eb274e620d8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "Number of GPUs available: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node while/range defined at (most recent call last):\n  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n\n  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n\n  File \"<ipython-input-4-6e1f0a01843c>\", line 16, in compute_multiples_sum\n\nDetected at node while/range defined at (most recent call last):\n  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n\n  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n\n  File \"<ipython-input-4-6e1f0a01843c>\", line 16, in compute_multiples_sum\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Requires start <= limit when delta > 0: 1410100000/1410065408\n\t [[{{node while/range}}]]\n\t [[while/body/_1/while/range/_26]]\n  (1) INVALID_ARGUMENT:  Requires start <= limit when delta > 0: 1410100000/1410065408\n\t [[{{node while/range}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_sum_multiples_2230]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8a77b3fc8284>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Execute the optimized function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0msum_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_sum_multiples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The sum of multiples of 3 or 5 below {LIMIT} is: {sum_result.numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node while/range defined at (most recent call last):\n  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n\n  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n\n  File \"<ipython-input-4-6e1f0a01843c>\", line 16, in compute_multiples_sum\n\nDetected at node while/range defined at (most recent call last):\n  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n\n  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n\n  File \"<ipython-input-4-6e1f0a01843c>\", line 16, in compute_multiples_sum\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Requires start <= limit when delta > 0: 1410100000/1410065408\n\t [[{{node while/range}}]]\n\t [[while/body/_1/while/range/_26]]\n  (1) INVALID_ARGUMENT:  Requires start <= limit when delta > 0: 1410100000/1410065408\n\t [[{{node while/range}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_sum_multiples_2230]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Number of GPUs available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Initialize TensorFlow distribution strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define the limit for the computation\n",
        "LIMIT = 10**12  # Adjust as needed\n",
        "BATCH_SIZE = 10**5  # Reduce if necessary, consider dynamic adjustment\n",
        "\n",
        "def compute_multiples_sum(batch_start, batch_end):\n",
        "    # Place the range operation explicitly on CPU to save GPU memory\n",
        "    with tf.device('/CPU:0'):\n",
        "        numbers = tf.range(batch_start, batch_end, dtype=tf.int32)  # Using tf.int32\n",
        "    mask = tf.logical_or(tf.equal(numbers % 3, 0), tf.equal(numbers % 5, 0))\n",
        "    selected_numbers = tf.boolean_mask(numbers, mask)\n",
        "    return tf.reduce_sum(selected_numbers)\n",
        "\n",
        "# Using TensorFlow distribution strategy\n",
        "with strategy.scope():\n",
        "    @tf.function\n",
        "    def distributed_sum_multiples(limit):\n",
        "        num_batches = (limit + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "        total_sum = tf.constant(0, dtype=tf.int32)\n",
        "\n",
        "        for batch_index in tf.range(num_batches):\n",
        "            batch_start = batch_index * BATCH_SIZE\n",
        "            batch_end = tf.minimum((batch_index + 1) * BATCH_SIZE, limit)\n",
        "            if batch_start < batch_end:  # Ensure batch_start is less than batch_end\n",
        "                batch_sum = strategy.run(compute_multiples_sum, args=(batch_start, batch_end))\n",
        "                total_sum += strategy.reduce(tf.distribute.ReduceOp.SUM, batch_sum, axis=None)\n",
        "\n",
        "        return total_sum\n",
        "\n",
        "# Execute the optimized function\n",
        "sum_result = distributed_sum_multiples(LIMIT)\n",
        "print(f\"The sum of multiples of 3 or 5 below {LIMIT} is: {sum_result.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK7JCJvSkpVd",
        "outputId": "28bb4c1b-4f1b-4011-d1d0-b8480eff1641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "Number of GPUs available: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Number of GPUs available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Initialize TensorFlow distribution strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define the limit for the computation\n",
        "LIMIT = 10**12  # Adjust as needed\n",
        "BATCH_SIZE = 10**5  # Reduce if necessary, consider dynamic adjustment\n",
        "\n",
        "def compute_multiples_sum(batch_start, batch_end):\n",
        "    # Execute range operation on CPU to manage memory use more efficiently\n",
        "    with tf.device('/CPU:0'):\n",
        "        numbers = tf.range(batch_start, batch_end, dtype=tf.int32)  # Using tf.int32\n",
        "\n",
        "    # Execute mathematical operations on GPU for better performance\n",
        "    with tf.device('/GPU:0'):\n",
        "        mask = tf.logical_or(tf.equal(numbers % 3, 0), tf.equal(numbers % 5, 0))\n",
        "        selected_numbers = tf.boolean_mask(numbers, mask)\n",
        "        return tf.reduce_sum(selected_numbers)\n",
        "\n",
        "# Using TensorFlow distribution strategy\n",
        "with strategy.scope():\n",
        "    @tf.function\n",
        "    def distributed_sum_multiples(limit):\n",
        "        num_batches = (limit + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "        total_sum = tf.constant(0, dtype=tf.int32)\n",
        "\n",
        "        for batch_index in tf.range(num_batches):\n",
        "            batch_start = batch_index * BATCH_SIZE\n",
        "            batch_end = tf.minimum((batch_index + 1) * BATCH_SIZE, limit)\n",
        "            if batch_start < batch_end:  # Ensure batch_start is less than batch_end\n",
        "                batch_sum = strategy.run(compute_multiples_sum, args=(batch_start, batch_end))\n",
        "                total_sum += strategy.reduce(tf.distribute.ReduceOp.SUM, batch_sum, axis=None)\n",
        "\n",
        "        return total_sum\n",
        "\n",
        "# Execute the optimized function\n",
        "sum_result = distributed_sum_multiples(LIMIT)\n",
        "print(f\"The sum of multiples of 3 or 5 below {LIMIT} is: {sum_result.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VHPfYaJlG9u",
        "outputId": "a9d757c2-7310-4765-f832-27b861db334e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "Number of GPUs available: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Number of GPUs available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Initialize TensorFlow distribution strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define the limit for the computation\n",
        "LIMIT = 10**12\n",
        "BATCH_SIZE = 10**5\n",
        "\n",
        "def prepare_data(batch_start, batch_end):\n",
        "    # This function runs on CPU for data preparation\n",
        "    with tf.device('/CPU:0'):\n",
        "        numbers = tf.range(batch_start, batch_end, dtype=tf.int32)\n",
        "        mask = tf.logical_or(tf.equal(numbers % 3, 0), tf.equal(numbers % 5, 0))\n",
        "        selected_numbers = tf.boolean_mask(numbers, mask)\n",
        "    return selected_numbers\n",
        "\n",
        "def sum_numbers(selected_numbers):\n",
        "    # This function runs on GPU for computation\n",
        "    with tf.device('/GPU:0'):\n",
        "        return tf.reduce_sum(selected_numbers)\n",
        "\n",
        "# Using TensorFlow distribution strategy\n",
        "with strategy.scope():\n",
        "    @tf.function\n",
        "    def distributed_sum_multiples(limit):\n",
        "        num_batches = (limit + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "        total_sum = tf.constant(0, dtype=tf.int32)\n",
        "\n",
        "        for batch_index in tf.range(num_batches):\n",
        "            batch_start = batch_index * BATCH_SIZE\n",
        "            batch_end = tf.minimum((batch_index + 1) * BATCH_SIZE, limit)\n",
        "            if batch_start < batch_end:  # Ensure batch_start is less than batch_end\n",
        "                selected_numbers = strategy.run(prepare_data, args=(batch_start, batch_end))\n",
        "                batch_sum = strategy.run(sum_numbers, args=(selected_numbers,))\n",
        "                total_sum += strategy.reduce(tf.distribute.ReduceOp.SUM, batch_sum, axis=None)\n",
        "\n",
        "        return total_sum\n",
        "\n",
        "# Execute the optimized function\n",
        "sum_result = distributed_sum_multiples(LIMIT)\n",
        "print(f\"The sum of multiples of 3 or 5 below {LIMIT} is: {sum_result.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZzVtdAalube",
        "outputId": "8a0d5e1b-2279-4cde-cb52-524da799bdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "Number of GPUs available: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GYDr3D-mPIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}